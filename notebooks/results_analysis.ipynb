{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from utils import get_data, onehot_encoding, grid_search, save_dict_to_file, load_dict_from_file\n",
    "from Layer import Layer, Input\n",
    "from functions import accuracy, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/best_comb9.pkl'\n",
    "param_grid_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/param_grid9.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/MONK/monks-3.train')\n",
    "df_test = get_data('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/MONK/monks-3.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df.drop(columns=['target','id']).to_numpy().T, df['target'].apply(lambda x: int(x)).to_numpy().T\n",
    "X_test, y_test = df_test.drop(columns=['target','id']).to_numpy().T, df_test['target'].apply(lambda x: int(x)).to_numpy().T\n",
    "\n",
    "# DATA PREPARATION\n",
    "\n",
    "X_train = onehot_encoding(X_train)\n",
    "X_test = onehot_encoding(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb = load_dict_from_file(best_comb_filename)\n",
    "param_grid = load_dict_from_file(param_grid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_best = []\n",
    "for p_comb in param_grid:\n",
    "    if p_comb['results']['val_accuracy_mean'] > 90 and p_comb['hidden_act_func'] == 'sigm':\n",
    "        print(p_comb)\n",
    "        p_best.append(p_comb)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 26,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 2.58e-01 +- 9.76e-02\n",
      "val_accuracy = 9.43e+01 +- 3.25e+00\n",
      "hyperparameters : {'eta': 0.09, 'lam': 1e-05, 'alpha': 0.1, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': False, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 6.415842294692993}\n",
      "results : {'train_loss_mean': 0.1669087107523081, 'train_loss_std': 0.015779543816278586, 'val_loss_mean': 0.2575597145082854, 'val_loss_std': 0.09758677348168854, 'train_accuracy_mean': 94.06462585034015, 'train_accuracy_std': 0.9686415555032775, 'val_accuracy_mean': 94.2948717948718, 'val_accuracy_std': 3.2458945900441485, 'train_MSE_mean': 0.04174065296457485, 'train_MSE_std': 0.003505326221145587, 'val_MSE_mean': 0.06443479157686852, 'val_MSE_std': 0.026472874118565838}\n",
      "\n",
      "val_loss = 2.74e-01 +- 1.61e-01\n",
      "val_accuracy = 9.42e+01 +- 4.25e+00\n",
      "hyperparameters : {'eta': 0.085, 'lam': 8e-06, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': False, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 5.676792621612549}\n",
      "results : {'train_loss_mean': 0.12851507706320744, 'train_loss_std': 0.024515313856240426, 'val_loss_mean': 0.2738148790903336, 'val_loss_std': 0.16110485792592252, 'train_accuracy_mean': 95.48469387755102, 'train_accuracy_std': 1.4148392473328613, 'val_accuracy_mean': 94.16666666666667, 'val_accuracy_std': 4.24918292799399, 'train_MSE_mean': 0.03462053611372154, 'train_MSE_std': 0.006751889349090889, 'val_MSE_mean': 0.06614682096820627, 'val_MSE_std': 0.038035984288794455}\n",
      "\n",
      "val_loss = 2.66e-01 +- 1.51e-01\n",
      "val_accuracy = 9.42e+01 +- 5.65e+00\n",
      "hyperparameters : {'eta': 0.09, 'lam': 8e-06, 'alpha': 0.3, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': False, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 7.143913984298706}\n",
      "results : {'train_loss_mean': 0.15562428281947588, 'train_loss_std': 0.03530931127448962, 'val_loss_mean': 0.2656018251385629, 'val_loss_std': 0.15134873790223685, 'train_accuracy_mean': 94.25595238095238, 'train_accuracy_std': 0.8688878535732298, 'val_accuracy_mean': 94.16666666666667, 'val_accuracy_std': 5.651941652604391, 'train_MSE_mean': 0.04037388592586939, 'train_MSE_std': 0.009581771120580469, 'val_MSE_mean': 0.06438642833253759, 'val_MSE_std': 0.042301161770806284}\n",
      "\n",
      "val_loss = 2.84e-01 +- 2.21e-01\n",
      "val_accuracy = 9.37e+01 +- 7.15e+00\n",
      "hyperparameters : {'eta': 0.09, 'lam': 8e-06, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': False, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 6.469361066818237}\n",
      "results : {'train_loss_mean': 0.1252504176974467, 'train_loss_std': 0.02913137057526204, 'val_loss_mean': 0.28367309008075886, 'val_loss_std': 0.2209432577758926, 'train_accuracy_mean': 95.90561224489795, 'train_accuracy_std': 1.4342543670276093, 'val_accuracy_mean': 93.65384615384616, 'val_accuracy_std': 7.145063996457831, 'train_MSE_mean': 0.03188794054690216, 'train_MSE_std': 0.009698269426549088, 'val_MSE_mean': 0.06703078724762297, 'val_MSE_std': 0.06354863118434811}\n",
      "\n",
      "val_loss = 2.82e-01 +- 1.21e-01\n",
      "val_accuracy = 9.36e+01 +- 5.20e+00\n",
      "hyperparameters : {'eta': 0.1, 'lam': 1e-05, 'alpha': 0.09, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': True, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 6.0769312381744385}\n",
      "results : {'train_loss_mean': 0.15582431865263477, 'train_loss_std': 0.02936630922550702, 'val_loss_mean': 0.28164433779132286, 'val_loss_std': 0.12140647008883972, 'train_accuracy_mean': 94.47704081632654, 'train_accuracy_std': 1.6392167169813583, 'val_accuracy_mean': 93.5897435897436, 'val_accuracy_std': 5.203770190410876, 'train_MSE_mean': 0.039556108007384586, 'train_MSE_std': 0.008875628697162258, 'val_MSE_mean': 0.07000851200884477, 'val_MSE_std': 0.03507701882480281}\n",
      "\n",
      "val_loss = 2.73e-01 +- 1.58e-01\n",
      "val_accuracy = 9.35e+01 +- 4.79e+00\n",
      "hyperparameters : {'eta': 0.1, 'lam': 8e-06, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': True, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 5.749350070953369}\n",
      "results : {'train_loss_mean': 0.10726741165488016, 'train_loss_std': 0.018507403620116134, 'val_loss_mean': 0.272574115248432, 'val_loss_std': 0.15845291926660535, 'train_accuracy_mean': 95.7015306122449, 'train_accuracy_std': 1.1770685709244197, 'val_accuracy_mean': 93.52564102564104, 'val_accuracy_std': 4.785847808956437, 'train_MSE_mean': 0.028288449573835785, 'train_MSE_std': 0.004597526204998522, 'val_MSE_mean': 0.0656478622766949, 'val_MSE_std': 0.03755972524794214}\n",
      "\n",
      "val_loss = 2.87e-01 +- 1.01e-01\n",
      "val_accuracy = 9.35e+01 +- 3.00e+00\n",
      "hyperparameters : {'eta': 0.085, 'lam': 3e-05, 'alpha': 0.1, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': True, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 5.790344476699829}\n",
      "results : {'train_loss_mean': 0.17979775480544813, 'train_loss_std': 0.023999847462861632, 'val_loss_mean': 0.2874726555081668, 'val_loss_std': 0.10084542612504808, 'train_accuracy_mean': 94.47278911564626, 'train_accuracy_std': 1.2049652778175737, 'val_accuracy_mean': 93.52564102564104, 'val_accuracy_std': 3.0025739560590776, 'train_MSE_mean': 0.04436056845795387, 'train_MSE_std': 0.007390999776209892, 'val_MSE_mean': 0.07083325825301479, 'val_MSE_std': 0.03077223698354088}\n",
      "\n",
      "val_loss = 2.86e-01 +- 1.15e-01\n",
      "val_accuracy = 9.35e+01 +- 3.00e+00\n",
      "hyperparameters : {'eta': 0.085, 'lam': 5e-06, 'alpha': 0.09, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': True, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 6.424182415008545}\n",
      "results : {'train_loss_mean': 0.1789053892466149, 'train_loss_std': 0.03100773202305644, 'val_loss_mean': 0.2858410554434657, 'val_loss_std': 0.11469249521784818, 'train_accuracy_mean': 94.47704081632654, 'train_accuracy_std': 1.6392167169813583, 'val_accuracy_mean': 93.52564102564104, 'val_accuracy_std': 3.0025739560590776, 'train_MSE_mean': 0.04340683688323409, 'train_MSE_std': 0.008132482363901721, 'val_MSE_mean': 0.07179737211781223, 'val_MSE_std': 0.02387241341354661}\n",
      "\n",
      "val_loss = 2.61e-01 +- 8.86e-02\n",
      "val_accuracy = 9.35e+01 +- 3.00e+00\n",
      "hyperparameters : {'eta': 0.09, 'lam': 8e-06, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': True, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 6.363001346588135}\n",
      "results : {'train_loss_mean': 0.13038803796490425, 'train_loss_std': 0.00920238768653181, 'val_loss_mean': 0.2606415025643815, 'val_loss_std': 0.0885993025316387, 'train_accuracy_mean': 94.88520408163265, 'train_accuracy_std': 1.0945631608635173, 'val_accuracy_mean': 93.52564102564104, 'val_accuracy_std': 3.0025739560590776, 'train_MSE_mean': 0.03370676498152356, 'train_MSE_std': 0.003355413517572968, 'val_MSE_mean': 0.06503743851371066, 'val_MSE_std': 0.027069264963730525}\n",
      "\n",
      "val_loss = 2.67e-01 +- 7.38e-02\n",
      "val_accuracy = 9.35e+01 +- 3.00e+00\n",
      "hyperparameters : {'eta': 0.08, 'lam': 3e-05, 'alpha': 0.1, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 4, 'hidden_act_func': 'tanh', 'l1_reg': True, 'nest': False, 'loss': 'binary_crossentropy', 'output_act_func': 'sigm', 'elapsed_time': 5.823898792266846}\n",
      "results : {'train_loss_mean': 0.17726266297452234, 'train_loss_std': 0.016280573568842296, 'val_loss_mean': 0.26738179088626657, 'val_loss_std': 0.0738138555072247, 'train_accuracy_mean': 93.65221088435374, 'train_accuracy_std': 0.9743354462179192, 'val_accuracy_mean': 93.52564102564104, 'val_accuracy_std': 3.0025739560590776, 'train_MSE_mean': 0.0448242540062217, 'train_MSE_std': 0.005417220863702051, 'val_MSE_mean': 0.06510037263311388, 'val_MSE_std': 0.022836430192721642}\n",
      "\n"
     ]
<<<<<<< HEAD
=======
    }
   ],
   "source": [
    "how_many = 10 # how many elements to print\n",
    "sorting_key = 'val_accuracy_mean' # value on which the sorting is performed\n",
    "p_best = []\n",
    "\n",
    "p_to_sort = [[x, x['results'][sorting_key]] for x in param_grid]\n",
    "p_best_sorted = sorted(p_to_sort, key=lambda x:-x[1])\n",
    "\n",
    "for p_comb,loss in p_best_sorted[:how_many]:\n",
    "    p_best.append(p_comb)\n",
    "    tmp_dict = p_comb.copy()\n",
    "    results = tmp_dict.pop('results')\n",
    "    print(f\"val_loss = {results['val_loss_mean']:.2e} +- {results['val_loss_std']:.2e}\")\n",
    "    print(f\"val_accuracy = {results['val_accuracy_mean']:.2e} +- {results['val_accuracy_std']:.2e}\")\n",
    "    print(f'hyperparameters : {tmp_dict}')\n",
    "    print(f'results : {results}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NeuralNetwork.retrain() got an unexpected keyword argument 'l1_reg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Layer(hidden_layer, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer, output_layer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[accuracy, MSE])\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_comb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''plt.figure(1)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mplt.plot(history['train_loss'],label='train_loss')\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mplt.plot(history['test_loss'], label='test_loss')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03mplt.grid()\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mplt.legend(fontsize=15)'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(i, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: NeuralNetwork.retrain() got an unexpected keyword argument 'l1_reg'"
     ]
>>>>>>> main
    }
   ],
   "source": [
    "how_many = 10 # how many elements to print\n",
    "sorting_key = 'val_accuracy_mean' # value on which the sorting is performed\n",
    "p_best = []\n",
    "\n",
    "p_to_sort = [[x, x['results'][sorting_key]] for x in param_grid]\n",
    "p_best_sorted = sorted(p_to_sort, key=lambda x:-x[1])\n",
    "\n",
    "for p_comb,loss in p_best_sorted[:how_many]:\n",
    "    p_best.append(p_comb)\n",
    "    tmp_dict = p_comb.copy()\n",
    "    results = tmp_dict.pop('results')\n",
    "    print(f\"val_loss = {results['val_loss_mean']:.2e} +- {results['val_loss_std']:.2e}\")\n",
    "    print(f\"val_accuracy = {results['val_accuracy_mean']:.2e} +- {results['val_accuracy_std']:.2e}\")\n",
    "    print(f'hyperparameters : {tmp_dict}')\n",
    "    print(f'results : {results}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p_comb in enumerate(p_best):\n",
    "\n",
    "    best_comb = p_comb.copy()\n",
    "\n",
    "    results = best_comb.pop('results')\n",
    "    if best_comb['n_batch'] == 'batch':\n",
    "        best_comb['n_batch'] = X_train.shape[1]\n",
    "    elapsed_time = best_comb.pop('elapsed_time')\n",
    "    if best_comb['scale_eta_batchsize'] == 'lin':\n",
    "        best_comb['eta'] = best_comb['eta'] * best_comb['n_batch']\n",
    "    if best_comb['scale_eta_batchsize'] == 'sqrt':\n",
    "        best_comb['eta'] = best_comb['eta'] * np.sqrt(best_comb['n_batch'])\n",
    "    best_comb.pop('scale_eta_batchsize')\n",
    "\n",
    "    #print(best_comb)\n",
    "    #print(results)\n",
    "    \n",
    "    input_layer = Input(X_train.shape[0])\n",
    "    hidden_layer = Layer(input_layer, best_comb.pop('dim_hidden'), best_comb.pop('hidden_act_func'))\n",
    "    output_layer = Layer(hidden_layer, 1, 'sigm')\n",
    "\n",
    "    model = NeuralNetwork(input_layer, output_layer, 'binary_crossentropy', metrics=[accuracy, MSE])\n",
    "    history = model.retrain(X_train, y_train.reshape((1,X_train.shape[1])), test_data = [X_test,y_test.reshape((1,X_test.shape[1]))], **best_comb)\n",
    "\n",
    "    '''plt.figure(1)\n",
    "    plt.plot(history['train_loss'],label='train_loss')\n",
    "    plt.plot(history['test_loss'], label='test_loss')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Loss functions', size=15)\n",
    "    plt.title('train_loss vs test_loss', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(history['train_accuracy'],label='train_accuracy')\n",
    "    plt.plot(history['test_accuracy'], label='test_accuracy')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Accuracy', size=15)\n",
    "    plt.title('train_accuracy vs test_accuracy', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)'''\n",
    "\n",
    "    plt.figure(i, figsize=(30,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['train_MSE'],label='train_MSE')\n",
    "    plt.plot(history['test_MSE'], label='test_MSE')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Accuracy', size=15)\n",
    "    plt.title('train_MSE vs test_MSE', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['train_accuracy'],label='train_accuracy')\n",
    "    plt.plot(history['test_accuracy'], label='test_accuracy')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Accuracy', size=15)\n",
    "    plt.title('train_accuracy vs test_accuracy', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
