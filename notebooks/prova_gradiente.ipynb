{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3., -2.,  2.,  5.]),)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = (torch.tensor([-2., -1., 1., 4.]),)\n",
    "values = torch.tensor([4., 1., 1., 16.], )\n",
    "torch.gradient(values, spacing = coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        input_layer = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100, 2)\n",
      "(2, 100, 2)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "N = 100 #dimensione pattern\n",
    "dim_input = 5 #dimensione input\n",
    "dim_hl = 3 #dimensione hidden layer\n",
    "dim_ol = 2 #dimensione output layer\n",
    "\n",
    "input = np.ones((N,dim_input))\n",
    "target = np.ones((N,dim_ol))\n",
    "\n",
    "w_ji = np.ones((dim_hl, dim_input))\n",
    "w_kj = np.ones((dim_ol, dim_hl))\n",
    "\n",
    "hidden = np.ones((N,dim_hl))\n",
    "output = np.ones((N,dim_ol))\n",
    "\n",
    "def f_act_out(x):\n",
    "    '''Linear activation function'''\n",
    "    return x\n",
    "\n",
    "def f_act_hidden(x):\n",
    "    '''Sigmoid activation function'''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Forward computation\n",
    "hidden = f_act_hidden(input @ w_ji.T)\n",
    "output = f_act_out(hidden @ w_kj.T)\n",
    "print(output.shape)\n",
    "#print(output)\n",
    "#Computation of errors at output layer\n",
    "print((hidden @ w_kj.T).shape)\n",
    "delta_k = np.array(np.gradient(output)) \n",
    "print(delta_k.shape)\n",
    "print((output-target).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\prova_gradiente.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/notebooks/prova_gradiente.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39;49mgradient(\u001b[39minput\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m))\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:1153\u001b[0m, in \u001b[0;36mgradient\u001b[1;34m(f, axis, edge_order, *varargs)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     axes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mrange\u001b[39m(N))\n\u001b[0;32m   1152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1153\u001b[0m     axes \u001b[39m=\u001b[39m _nx\u001b[39m.\u001b[39;49mnormalize_axis_tuple(axis, N)\n\u001b[0;32m   1155\u001b[0m len_axes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(axes)\n\u001b[0;32m   1156\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(varargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:1380\u001b[0m, in \u001b[0;36mnormalize_axis_tuple\u001b[1;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[39m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[1;32m-> 1380\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[39mfor\u001b[39;49;00m ax \u001b[39min\u001b[39;49;00m axis])\n\u001b[0;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_duplicate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(axis)) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(axis):\n\u001b[0;32m   1382\u001b[0m     \u001b[39mif\u001b[39;00m argname:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:1380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[39m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[1;32m-> 1380\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m axis])\n\u001b[0;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_duplicate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(axis)) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(axis):\n\u001b[0;32m   1382\u001b[0m     \u001b[39mif\u001b[39;00m argname:\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "np.array(np.gradient(input,axis=input)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[0. 0.]\n",
      "[0. 0.]\n",
      "[1.97992145 1.97992145]\n"
     ]
    }
   ],
   "source": [
    "#N = 100 #dimensione pattern\n",
    "dim_input = 5 #dimensione input\n",
    "dim_hl = 3 #dimensione hidden layer\n",
    "dim_ol = 2 #dimensione output layer\n",
    "\n",
    "input = np.ones(dim_input)\n",
    "target = np.ones(dim_ol)\n",
    "\n",
    "w_ji = np.ones((dim_hl, dim_input))\n",
    "w_kj = np.ones((dim_ol, dim_hl))\n",
    "\n",
    "hidden = np.ones(dim_hl)\n",
    "output = np.ones(dim_ol)\n",
    "\n",
    "def f_act_out(x):\n",
    "    '''Linear activation function'''\n",
    "    return x\n",
    "\n",
    "def f_act_hidden(x):\n",
    "    '''Sigmoid activation function'''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Forward computation\n",
    "hidden = f_act_hidden(input @ w_ji.T)\n",
    "output = f_act_out(hidden @ w_kj.T)\n",
    "print(output.shape)\n",
    "#print(output)\n",
    "#Computation of errors at output layer\n",
    "print(np.array(np.gradient(output)))\n",
    "delta_k = (output-target) * np.array(np.gradient(output)) \n",
    "print(delta_k)\n",
    "print((output-target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
