{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sn\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    df = pd.read_csv(filename, names = ['all'])\n",
    "    df['all'] = df['all'].str.strip()\n",
    "    df['all1']  = df['all'].apply(lambda x: np.array(x.split(' ')))\n",
    "    df[['target','attr1','attr2','attr3','attr4','attr5','attr6','id']] = pd.DataFrame(df.all1.tolist(), index= df.index)\n",
    "    return df.drop(columns=['all','all1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(r\"\\Users\\s512fj-ej021t\\OneDrive\\Desktop\\ML\\monks-1.train\")\n",
    "df_test = get_data(r\"\\Users\\s512fj-ej021t\\OneDrive\\Desktop\\ML\\monks-1.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df.drop(columns=['target','id']), df['target'].apply(lambda x: int(x))\n",
    "X_test, y_test = df_test.drop(columns=['target','id']), df_test['target'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train, y_train)\n",
    "X_train = ohe.transform(X_train).toarray()\n",
    "X_test = ohe.transform(X_test).toarray()\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#linear activation function \n",
    "def linear(x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    return x\n",
    "\n",
    "def d_linear(x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    return 1\n",
    "\n",
    "#sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    f =sigmoid(x)\n",
    "    return f * (1-f)\n",
    "\n",
    "#ReLu activation function\n",
    "def relu(x):\n",
    "    if x > 0: return x\n",
    "    else: return 0\n",
    "\n",
    "def d_relu(x):\n",
    "    if x > 0: return 1\n",
    "    else: return 0\n",
    "    \n",
    "\n",
    "#hyperbolic tangent activation function\n",
    "def TanH(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def d_TanH(x):\n",
    "    return 1 - math.pow(np.tanh(x), 2) \n",
    "\n",
    "#Dictionary for the activation functions\n",
    "act_func = {\n",
    "    'lin': linear,\n",
    "    'sigm': sigmoid,\n",
    "    'relu': relu,\n",
    "    'tanh': TanH\n",
    "}\n",
    "\n",
    "#A second dictionary for their derivatives\n",
    "d_act_func = {\n",
    "    'lin': d_linear,\n",
    "    'sigm': d_sigmoid,\n",
    "    'relu': d_relu,\n",
    "    'tanh': d_TanH\n",
    "}\n",
    "\n",
    "def MSE(layer, target):\n",
    "    return (layer - target)/target.shape[1]\n",
    "\n",
    "def binary_crossentropy(layer, target):\n",
    "    return (layer - target)/(layer*(1-layer)*target.shape[1])\n",
    "\n",
    "class Layer:\n",
    "\n",
    "    def __init__(self, input, prev_layer, dim_layer, act_function, target):\n",
    "  \n",
    "        self.prev_layer = prev_layer\n",
    "        self.target = target\n",
    "        self.init_params(dim_layer, act_function, input)\n",
    "\n",
    "    def init_params(self, dim_layer, act_function, input):\n",
    "        self.dim_batch = self.prev_layer.dim_batch\n",
    "        self.dim_layer = dim_layer\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (dim_layer, self.prev_layer.dim_layer))    #inizializzo la matrice dei pesi\n",
    "        self.b = np.random.uniform(-0.5, 0.5, (dim_layer, 1))      #inizializzo il vettore dei bias\n",
    "        self.layer = np.empty((dim_layer, self.dim_batch))\n",
    "        self.act_function = np.vectorize(act_func[act_function])\n",
    "        self.d_act_function = np.vectorize(d_act_func[act_function])\n",
    "\n",
    "    def forward(self, mode = 'train'):\n",
    "        if mode == 'train':\n",
    "            self.z = self.W.dot(self.prev_layer.forward()) + self.b\n",
    "            self.layer = self.act_function(self.z)\n",
    "            #print(f'layer = {self.layer}')\n",
    "            return self.layer\n",
    "        elif mode == 'predict':\n",
    "            return self.act_function(self.W.dot(self.prev_layer.forward()) + self.b)\n",
    "        \n",
    "    \n",
    "    def backward(self, next_delta = None, next_weights = None, lossfunc = None):\n",
    "        #print(f'Entered backward: target = {self.target}')\n",
    "        \n",
    "        if self.target is None:\n",
    "\n",
    "            #print('self.target == None: hidden')\n",
    "            delta = self.d_act_function(self.z) * next_weights.T.dot(next_delta)\n",
    "            #self.prev_layer.backward(delta,self.weights)\n",
    "            self.d_W = delta.dot(self.prev_layer.backward(delta,self.W).T)\n",
    "            self.d_b = delta.sum(axis=1).reshape((delta.shape[0],1))\n",
    "            return self.layer\n",
    "            \n",
    "        else:\n",
    "            #print('self.target != None: output')\n",
    "            #print(self.d_act_function(self.z).shape)\n",
    "            #print(lossfunc(self.layer,self.target).shape)\n",
    "            #print(self.layer.shape)\n",
    "            #print(self.target.shape)\n",
    "            delta = self.d_act_function(self.z) * lossfunc(self.layer,self.target)\n",
    "            #self.prev_layer.backward(delta,self.weights)\n",
    "            self.d_W = delta.dot(self.prev_layer.backward(delta,self.W).T)\n",
    "            self.d_b = delta.sum(axis=1).reshape((delta.shape[0],1))\n",
    "            return self.layer    \n",
    "\n",
    "    def update_weights(self, eta, lam):\n",
    "\n",
    "        self.W = self.W - eta * self.d_W - lam * self.W\n",
    "        self.prev_layer.update_weights(eta, lam)\n",
    "\n",
    "    def err(self):\n",
    "        return np.sqrt((self.layer[0]-self.target[0])**2+(self.layer[1]-self.target[1])**2+(self.layer[2]-self.target[2])**2).mean()\n",
    "    \n",
    "    def rel_err(self):\n",
    "        return np.sqrt((self.layer[0]-self.target[0])**2/self.target[0]**2+(self.layer[1]-self.target[1])**2/self.target[1]**2+(self.layer[2]-self.target[2])**2/self.target[2]**2).mean()\n",
    "\n",
    "    def err_i(self,i):\n",
    "        return np.sqrt((self.layer[i]-self.target[i])**2).mean()\n",
    "    \n",
    "    def rel_err_i(self,i):\n",
    "        return (np.sqrt((self.layer[i]-self.target[i])**2)/self.target[i]).mean()\n",
    "    \n",
    "class Input(Layer):\n",
    "\n",
    "    def __init__(self, input, input_dim):\n",
    "\n",
    "        Layer.__init__(self, input, None, input_dim, 'lin', None)\n",
    "\n",
    "    def init_params(self, dim_layer, act_function, input):\n",
    "        self.layer = input\n",
    "        self.dim_batch = input.shape[1]\n",
    "        self.dim_layer = dim_layer\n",
    "\n",
    "    def forward(self,mode = 'train'):\n",
    "        return self.layer\n",
    "    \n",
    "    def backward(self, next_delta = None, next_weights = None):\n",
    "        return self.layer\n",
    "    \n",
    "    def update_weights(self, eta, lam):\n",
    "        return self.layer\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc = {'MSE':MSE,\n",
    "            'binary_crossentropy':binary_crossentropy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self,input_layer,output_layer,loss):\n",
    "        self.input_layer = input_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.lossfunc = lossfunc[loss]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #def add_layer():\n",
    "\n",
    "    def predict(self,input):\n",
    "        self.input_layer.layer = input\n",
    "        self.output_layer.forward(mode = 'predict')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def train(self,input,target,epoche,eta,lam,n_batch,validation_split): #callbacks\n",
    "        #print(np.floor(validation_split*input.shape[1]).astype(int))\n",
    "        #print(input.shape,target.shape)\n",
    "        val_input = input[:,np.floor(validation_split*input.shape[1]).astype(int):]\n",
    "        val_target = target[:,np.floor(validation_split*input.shape[1]).astype(int):]\n",
    "        train_input = input[:,:np.floor(validation_split*input.shape[1]).astype(int)]\n",
    "        train_target = target[:,:np.floor(validation_split*input.shape[1]).astype(int)]\n",
    "\n",
    "        index = np.arange(len(train_input))\n",
    "    \n",
    "\n",
    "\n",
    "        j = 0\n",
    "        while j < epoche:\n",
    "                if j%100 == 0:\n",
    "                     print(j)\n",
    "                np.random.shuffle(index)\n",
    "                input_new = train_input[:,index]\n",
    "                target_new = train_target[:,index]\n",
    "                #print(input_new.shape)\n",
    "                #print(target_new.shape)\n",
    "                \n",
    "                for k in range(input_new.shape[1]//n_batch):\n",
    "                    if k == input_new.shape[1]//n_batch -1:\n",
    "                        self.input_layer.input = input_new[:,k*n_batch:]\n",
    "                        self.output_layer.target = target_new[:,k*n_batch:]\n",
    "                    else:\n",
    "                        self.input_layer.input = input_new[:,k*n_batch:(k+1)*n_batch]\n",
    "                        self.output_layer.target = target_new[:,k*n_batch:(k+1)*n_batch]\n",
    "                    \n",
    "                    self.output_layer.forward()\n",
    "                    #self.trainloss.append(self.output_layer.trainloss())\n",
    "                    #self.validloss.append(self.output_layer.validloss())\n",
    "                    self.output_layer.backward(lossfunc = self.lossfunc)\n",
    "                    self.output_layer.update_weights(eta, lam)\n",
    "\n",
    "\n",
    "                j += 1\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(X_train, 17)\n",
    "hidden_layer = Layer(None, input_layer, 8, 'tanh', None)\n",
    "output_layer = Layer(None, hidden_layer, 1, 'sigm', y_train.to_numpy().reshape((1,124)))\n",
    "\n",
    "model = NeuralNetwork(input_layer,output_layer,'binary_crossentropy')\n",
    "model.train(X_train,y_train.to_numpy().reshape((1,124)),epoche = 1000,eta = 0.01,lam = 0.01,n_batch = 32,validation_split = 0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
