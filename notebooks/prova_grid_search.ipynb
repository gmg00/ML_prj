{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from functions import *\n",
    "from Layer import Layer, Input\n",
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/MONK/monks-1.train')\n",
    "df_test = get_data('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/MONK/monks-1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_data(r\"\\Users\\s512fj-ej021t\\OneDrive\\Desktop\\ML\\monks-1.train\")\n",
    "#df_test = get_data(r\"\\Users\\s512fj-ej021t\\OneDrive\\Desktop\\ML\\monks-1.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df.drop(columns=['target','id']).to_numpy().T, df['target'].apply(lambda x: int(x)).to_numpy().T\n",
    "X_test, y_test = df_test.drop(columns=['target','id']).to_numpy().T, df_test['target'].apply(lambda x: int(x)).to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = onehot_encoding(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'eta' : [0.005,0.01,0.05,0.1,0.5],\n",
    "          'lam' : [0.0, 0.01,0.03],\n",
    "          'alpha':[0.1,0.5,0.9],\n",
    "          'epochs': [500],\n",
    "          'n_batch' : [1, 31, 'batch'],\n",
    "          'scale_eta_batchsize' : ['sqrt','lin',None], #'sqrt' per eta * sqrt(n_batch), 'lin' per eta * n_batch\n",
    "          \n",
    "          'dim_hidden' : [2,3,4],\n",
    "          'hidden_act_func' : ['relu','tanh']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'eta' : [0.005,0.01,0.5],\n",
    "          'lam' : [0.0, 0.01],\n",
    "          'alpha':[0.5,0.9],\n",
    "          'epochs': [500],\n",
    "          'n_batch' : ['batch'],\n",
    "          'scale_eta_batchsize' : [None], #'sqrt' per eta * sqrt(n_batch), 'lin' per eta * n_batch\n",
    "          \n",
    "          'dim_hidden' : [2,3],\n",
    "          'hidden_act_func' : ['relu'],\n",
    "\n",
    "          'loss' : ['binary_crossentropy'],\n",
    "          'output_act_func' : ['sigm']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = {'patience' : 150,\n",
    "                  'monitor' : 'val_accuracy',\n",
    "                  'verbose' : 0,\n",
    "                  'compare_function': np.greater_equal}\n",
    "\n",
    "reduce_eta = {'patience' : 75,\n",
    "              'monitor' : 'val_accuracy',\n",
    "              'factor' : 0.5,\n",
    "              'verbose' : 0,\n",
    "              'compare_function': np.greater_equal}\n",
    "\n",
    "callbacks = {'early_stopping': None,\n",
    "             'reduce_eta': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid_search...\n",
      "Grid of parameters: {'eta': [0.005, 0.01, 0.5], 'lam': [0.0, 0.01], 'alpha': [0.5, 0.9], 'epochs': [500], 'n_batch': ['batch'], 'scale_eta_batchsize': [None], 'dim_hidden': [2, 3], 'hidden_act_func': ['relu'], 'loss': ['binary_crossentropy'], 'output_act_func': ['sigm']}\n",
      "-------------------------------------------------\n",
      "Starting params 1/24: {'eta': 0.005, 'lam': 0.0, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 2, 'hidden_act_func': 'relu', 'loss': 'binary_crossentropy', 'output_act_func': 'sigm'}\n",
      "Results:\n",
      "train_loss_mean: 2.07e-01\n",
      "train_loss_std: 6.28e-02\n",
      "val_loss_mean: 4.16e-01\n",
      "val_loss_std: 1.55e-01\n",
      "train_accuracy_mean: 9.25e+01\n",
      "train_accuracy_std: 3.76e+00\n",
      "val_accuracy_mean: 8.30e+01\n",
      "val_accuracy_std: 4.79e+00\n",
      "train_MSE_mean: 5.83e-02\n",
      "train_MSE_std: 2.40e-02\n",
      "val_MSE_mean: 1.25e-01\n",
      "val_MSE_std: 4.06e-02\n",
      "Elapsed time: 7.086872 s\n",
      "-------------------------------------------------\n",
      "Starting params 2/24: {'eta': 0.005, 'lam': 0.0, 'alpha': 0.5, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 3, 'hidden_act_func': 'relu', 'loss': 'binary_crossentropy', 'output_act_func': 'sigm'}\n",
      "Results:\n",
      "train_loss_mean: 1.04e-01\n",
      "train_loss_std: 4.85e-02\n",
      "val_loss_mean: 1.55e-01\n",
      "val_loss_std: 1.11e-01\n",
      "train_accuracy_mean: 9.66e+01\n",
      "train_accuracy_std: 2.90e+00\n",
      "val_accuracy_mean: 9.36e+01\n",
      "val_accuracy_std: 7.42e+00\n",
      "train_MSE_mean: 2.73e-02\n",
      "train_MSE_std: 1.88e-02\n",
      "val_MSE_mean: 4.26e-02\n",
      "val_MSE_std: 3.94e-02\n",
      "Elapsed time: 9.695910 s\n",
      "-------------------------------------------------\n",
      "Starting params 3/24: {'eta': 0.005, 'lam': 0.0, 'alpha': 0.9, 'epochs': 500, 'n_batch': 'batch', 'scale_eta_batchsize': None, 'dim_hidden': 2, 'hidden_act_func': 'relu', 'loss': 'binary_crossentropy', 'output_act_func': 'sigm'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_comb, param_grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mMSE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;241m166\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\utils.py:279\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(input, target, params, cv_folds, metrics, callbacks)\u001b[0m\n\u001b[0;32m    277\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    278\u001b[0m p_comb_copy  \u001b[38;5;241m=\u001b[39m p_comb\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 279\u001b[0m p_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_comb_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m p_comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melapsed_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\utils.py:222\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(input, target, folds, metrics, params, callbacks)\u001b[0m\n\u001b[0;32m    218\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Layer(hidden_layer, train_target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], output_act_func)\n\u001b[0;32m    220\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer, output_layer, loss, metrics \u001b[38;5;241m=\u001b[39m metrics)\n\u001b[1;32m--> 222\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_target\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m    226\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m history \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    229\u001b[0m     history_cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\NeuralNetwork.py:164\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[1;34m(self, input, target, epochs, eta, lam, alpha, n_batch, validation_split, validation_data, early_stopping, reduce_eta, verbose, use_opt)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m target_new[:, k:end_idx]\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mforward()\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlossfunc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_lossfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mupdate_weights(eta, lam, alpha, use_opt)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history_batch(history, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mforward(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:44\u001b[0m, in \u001b[0;36mLayer.backward\u001b[1;34m(self, next_delta, next_weights, lossfunc, last)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_act_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz) \u001b[38;5;241m*\u001b[39m lossfunc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_W \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_b \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((delta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:52\u001b[0m, in \u001b[0;36mLayer.backward\u001b[1;34m(self, next_delta, next_weights, lossfunc, last)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_act_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz) \u001b[38;5;241m*\u001b[39m next_weights\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(next_delta)\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_W \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_layer\u001b[38;5;241m.\u001b[39mbackward(delta,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_b \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((delta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_comb, param_grid = grid_search(X_train, y_train.reshape((1,X_train.shape[1])), params, 5, [accuracy,MSE], callbacks)\n",
    "166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.01,\n",
       " 'lam': 0.0,\n",
       " 'alpha': 0.5,\n",
       " 'epochs': 500,\n",
       " 'n_batch': 1,\n",
       " 'scale_eta_batchsize': None,\n",
       " 'dim_hidden': 3,\n",
       " 'hidden_act_func': 'relu',\n",
       " 'results': {'train_loss_mean': 0.12294714136838696,\n",
       "  'train_loss_std': 0.0506226861970321,\n",
       "  'val_loss_mean': 0.20320056148828286,\n",
       "  'val_loss_std': 0.09086906646796203,\n",
       "  'train_accuracy_mean': 97.98989898989899,\n",
       "  'train_accuracy_std': 2.4619127080841645,\n",
       "  'val_accuracy_mean': 97.6,\n",
       "  'val_accuracy_std': 4.800000000000001,\n",
       "  'train_MSE_metric_mean': 0.015107486359720673,\n",
       "  'train_MSE_metric_std': 0.01868979067643282,\n",
       "  'val_MSE_metric_mean': 0.022464635160999117,\n",
       "  'val_MSE_metric_std': 0.036266188039089015},\n",
       " 'elapsed_time': 108.96439099311829}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_file(dictionary, filename):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a file using pickle.\n",
    "\n",
    "    Parameters:\n",
    "    - dictionary: The dictionary to be saved.\n",
    "    - filename: The name of the file to save the dictionary to.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_file(best_comb,'/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/best_comb2.pkl')\n",
    "save_dict_to_file(param_grid,'/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/param_grid2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
