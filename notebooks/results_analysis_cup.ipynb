{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from utils import get_data, onehot_encoding, grid_search, save_dict_to_file, load_dict_from_file\n",
    "from Layer import Layer, Input\n",
    "from functions import accuracy, MSE, MEE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/best_comb_cup10.pkl'\n",
    "param_grid_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/param_grid_cup4.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['id', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', \n",
    "         'feature_7', 'feature_8', 'feature_9', 'feature_10', 'target_x', 'target_y','target_z']\n",
    "\n",
    "df = pd.read_csv('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/ML-CUP23-TR.csv', names=names, comment='#')\n",
    "\n",
    "targets = ['target_x', 'target_y', 'target_z']\n",
    "features = list(set(names) - {'id', 'target_x', 'target_y', 'target_z'})\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "prova = df[:750]\n",
    "X_train, y_train = prova[features].to_numpy().T, prova[targets].to_numpy().T\n",
    "X_test, y_test = df[750:][features].to_numpy().T, df[750:][targets].to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb = load_dict_from_file(best_comb_filename)\n",
    "param_grid = load_dict_from_file(param_grid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 3.78e-01 +- 1.13e-01\n",
      "val_MEE = 7.66e-01 +- 9.70e-02\n",
      "hyperparameters : {'eta': 0.003, 'lam': 3e-05, 'alpha': 0.9, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 70, 'hidden_act_func': 'tanh', 'dim_hidden2': 70, 'hidden_act_func2': 'tanh', 'use_opt': 0, 'loss': 'MSE', 'nest': True, 'output_act_func': 'lin', 'elapsed_time': 815.6306340694427}\n",
      "results : {'train_loss_mean': 0.09085061645304614, 'train_loss_std': 0.0034567101783981318, 'val_loss_mean': 0.37835700197048105, 'val_loss_std': 0.11343619843388787, 'train_MEE_mean': 0.43806295167109743, 'train_MEE_std': 0.011709663899263105, 'val_MEE_mean': 0.765610541097898, 'val_MEE_std': 0.09701997822883787}\n",
      "\n",
      "val_loss = 4.46e-01 +- 8.27e-02\n",
      "val_MEE = 8.49e-01 +- 4.68e-02\n",
      "hyperparameters : {'eta': 0.003, 'lam': 3e-05, 'alpha': 0.7, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 70, 'hidden_act_func': 'tanh', 'dim_hidden2': 70, 'hidden_act_func2': 'tanh', 'use_opt': 0, 'loss': 'MSE', 'nest': True, 'output_act_func': 'lin', 'elapsed_time': 818.2459726333618}\n",
      "results : {'train_loss_mean': 0.13633961933503247, 'train_loss_std': 0.008296517502726544, 'val_loss_mean': 0.44575465917127416, 'val_loss_std': 0.0827493610571545, 'train_MEE_mean': 0.5386636670650017, 'train_MEE_std': 0.01929615375867238, 'val_MEE_mean': 0.8487589548947956, 'val_MEE_std': 0.04675253678899905}\n",
      "\n",
      "val_loss = 6.96e-01 +- 3.82e-01\n",
      "val_MEE = 9.31e-01 +- 5.89e-02\n",
      "hyperparameters : {'eta': 0.001, 'lam': 3e-05, 'alpha': 0.9, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 70, 'hidden_act_func': 'tanh', 'dim_hidden2': 70, 'hidden_act_func2': 'tanh', 'use_opt': 0, 'loss': 'MSE', 'nest': True, 'output_act_func': 'lin', 'elapsed_time': 810.2885987758636}\n",
      "results : {'train_loss_mean': 0.24663131756223358, 'train_loss_std': 0.013884006359507038, 'val_loss_mean': 0.69639870414634, 'val_loss_std': 0.38211677110173464, 'train_MEE_mean': 0.6770512892404909, 'train_MEE_std': 0.014152715043893413, 'val_MEE_mean': 0.9309740727575606, 'val_MEE_std': 0.05890052806370428}\n",
      "\n",
      "val_loss = 6.46e-01 +- 1.68e-01\n",
      "val_MEE = 1.06e+00 +- 9.09e-02\n",
      "hyperparameters : {'eta': 0.001, 'lam': 3e-05, 'alpha': 0.7, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 70, 'hidden_act_func': 'tanh', 'dim_hidden2': 70, 'hidden_act_func2': 'tanh', 'use_opt': 0, 'loss': 'MSE', 'nest': True, 'output_act_func': 'lin', 'elapsed_time': 824.1670587062836}\n",
      "results : {'train_loss_mean': 0.3316641415286209, 'train_loss_std': 0.009259915545173384, 'val_loss_mean': 0.6458782088573144, 'val_loss_std': 0.16755926691422063, 'train_MEE_mean': 0.797143972520119, 'train_MEE_std': 0.013383990612556625, 'val_MEE_mean': 1.0601268522097196, 'val_MEE_std': 0.09085015027444843}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best {how_many} hyperparameter sets by their {sorting_key}\n",
    "\n",
    "how_many = 5 # how many elements to print\n",
    "sorting_key = 'val_MEE_mean' # value on which the sorting is performed\n",
    "p_best = []\n",
    "\n",
    "p_to_sort = [[x, x['results'][sorting_key]] for x in param_grid]\n",
    "p_best_sorted = sorted(p_to_sort, key=lambda x:x[1])\n",
    "\n",
    "for p_comb,loss in p_best_sorted[:how_many]:\n",
    "    p_best.append(p_comb)\n",
    "    tmp_dict = p_comb.copy()\n",
    "    results = tmp_dict.pop('results')\n",
    "    print(f\"val_loss = {results['val_loss_mean']:.2e} +- {results['val_loss_std']:.2e}\")\n",
    "    print(f\"val_MEE = {results['val_MEE_mean']:.2e} +- {results['val_MEE_std']:.2e}\")\n",
    "    print(f'hyperparameters : {tmp_dict}')\n",
    "    print(f'results : {results}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 1.995e+31, test_loss: 1.489e+31; train_MEE: 2.591e+15, test_MEE: 2.176e+15  lr : 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in leaky_relu (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Layer(hidden_layer, \u001b[38;5;241m3\u001b[39m, best_comb\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_act_func\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer, output_layer, best_comb\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[MEE])\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_comb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\NeuralNetwork.py:417\u001b[0m, in \u001b[0;36mNeuralNetwork.retrain\u001b[1;34m(self, input, target, epochs, eta, lam, alpha, n_batch, test_data, early_stopping, reduce_eta, verbose, use_opt, nest, l1_reg)\u001b[0m\n\u001b[0;32m    415\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history_batch(history, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mforward(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# Update history dictionary with batch-level validation loss and metrics information.\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history_batch(history, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m)\u001b[49m, test_target, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Update history dictionary with epoch-level information.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history_epoch(history, val_or_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\NeuralNetwork.py:47\u001b[0m, in \u001b[0;36mNeuralNetwork.predict\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Make prediction using the trained network.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    np.array: predictions made by the network.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m        \n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:112\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Compute layer matrix without updating its and net values.\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:112\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Compute layer matrix without updating its and net values.\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_layer\u001b[38;5;241m.\u001b[39mforward(mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Permorm retraining on the best {how_many} sets and print loss and MEE graphs.\n",
    "\n",
    "retraining_epochs = 250\n",
    "print_best = True # print the best results on all graphs\n",
    "\n",
    "for i,p_comb in enumerate(p_best):\n",
    "\n",
    "    best_comb = p_comb.copy()\n",
    "\n",
    "    best_comb['epochs'] = retraining_epochs\n",
    "\n",
    "    results = best_comb.pop('results')\n",
    "    if best_comb['n_batch'] == 'batch':\n",
    "        best_comb['n_batch'] = X_train.shape[1]\n",
    "    elapsed_time = best_comb.pop('elapsed_time')\n",
    "    if best_comb['scale_eta_batchsize'] == 'lin':\n",
    "        best_comb['eta'] = best_comb['eta'] * best_comb['n_batch']\n",
    "    if best_comb['scale_eta_batchsize'] == 'sqrt':\n",
    "        best_comb['eta'] = best_comb['eta'] * np.sqrt(best_comb['n_batch'])\n",
    "    best_comb.pop('scale_eta_batchsize')\n",
    "\n",
    "    # ----------------------- MODEL ----------------------------\n",
    "    \n",
    "    input_layer = Input(X_train.shape[0])\n",
    "    hidden_layer = Layer(input_layer, best_comb.pop('dim_hidden'), best_comb.pop('hidden_act_func'))\n",
    "    o = 2\n",
    "    while True:\n",
    "        if f'dim_hidden{o}' in best_comb.keys():\n",
    "            hidden_layer = Layer(hidden_layer, best_comb.pop(f'dim_hidden{o}'), best_comb.pop(f'hidden_act_func{o}'))\n",
    "            o += 1\n",
    "        else: break\n",
    "    output_layer = Layer(hidden_layer, 3, best_comb.pop('output_act_func'))\n",
    "\n",
    "    model = NeuralNetwork(input_layer, output_layer, best_comb.pop('loss'), metrics=[MEE])\n",
    "    history = model.retrain(X_train, y_train.reshape((3,X_train.shape[1])), test_data = [X_test,y_test.reshape((3,X_test.shape[1]))], **best_comb)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    if i == 0:\n",
    "        best_train_loss, best_test_loss = history['train_loss'], history['test_loss']\n",
    "        best_train_MEE, best_test_MEE = history['train_MEE'], history['test_MEE']\n",
    "\n",
    "    plt.figure(i, figsize=(30,10))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['train_loss'],label='train_loss')\n",
    "    plt.plot(history['test_loss'], label='test_loss')\n",
    "    if (i > 0) and (print_best == True):\n",
    "        plt.plot(best_train_loss,'--',label='best_train_loss')\n",
    "        plt.plot(best_test_loss, '--', label='best_test_loss')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Loss functions', size=15)\n",
    "    plt.title('train_loss vs test_loss', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['train_MEE'],label='train_MEE')\n",
    "    plt.plot(history['test_MEE'], label='test_MEE')\n",
    "    if (i > 0) and (print_best == True):\n",
    "        plt.plot(best_train_MEE,'--',label='best_train_MEE')\n",
    "        plt.plot(best_test_MEE, '--', label='best_test_MEE')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('MEE', size=15)\n",
    "    plt.title('train_MEE vs test_MEE', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(seed):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.58526844 2.1846418  6.79919952 7.11004665 7.14118482 0.5398932\n",
      " 0.13095949 8.0790181  8.17264435 3.85478113]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(function(232323))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
