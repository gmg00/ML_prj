{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from utils import get_data, onehot_encoding, grid_search, save_dict_to_file, load_dict_from_file\n",
    "from Layer import Layer, Input\n",
    "from functions import accuracy, MSE, MEE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/best_comb_cup2.pkl'\n",
    "param_grid_filename = '/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/output/param_grid_cup2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['id', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', \n",
    "         'feature_7', 'feature_8', 'feature_9', 'feature_10', 'target_x', 'target_y','target_z']\n",
    "\n",
    "df = pd.read_csv('/Users/HP/Desktop/UNI/LM_1/MachineLearning/ML_prj/data/ML-CUP23-TR.csv', names=names, comment='#')\n",
    "\n",
    "targets = ['target_x', 'target_y', 'target_z']\n",
    "features = list(set(names) - {'id', 'target_x', 'target_y', 'target_z'})\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "prova = df[:750]\n",
    "X_train, y_train = prova[features].to_numpy().T, prova[targets].to_numpy().T\n",
    "X_test, y_test = df[750:][features].to_numpy().T, df[750:][targets].to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb = load_dict_from_file(best_comb_filename)\n",
    "param_grid = load_dict_from_file(param_grid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 9.53e-01 +- 1.13e-01\n",
      "val_MEE = 1.40e+00 +- 6.19e-02\n",
      "hyperparameters : {'eta': 0.009, 'lam': 0.1, 'alpha': 1.2, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 25, 'hidden_act_func': 'leaky_relu', 'dim_hidden2': 30, 'hidden_act_func2': 'leaky_relu', 'dim_hidden3': 10, 'hidden_act_func3': 'leaky_relu', 'use_opt': 0, 'loss': 'MSE', 'output_act_func': 'lin', 'elapsed_time': 961.4998867511749}\n",
      "results : {'train_loss_mean': 0.6172068548431464, 'train_loss_std': 0.06985605292252886, 'val_loss_mean': 0.9533494896487491, 'val_loss_std': 0.11312852581938311, 'train_MEE_mean': 1.1745880551282362, 'train_MEE_std': 0.08077716558125936, 'val_MEE_mean': 1.4037974952022187, 'val_MEE_std': 0.06193356014637131}\n",
      "\n",
      "val_loss = 9.96e-01 +- 8.57e-02\n",
      "val_MEE = 1.41e+00 +- 4.75e-02\n",
      "hyperparameters : {'eta': 0.007, 'lam': 0.1, 'alpha': 0.9, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 25, 'hidden_act_func': 'leaky_relu', 'dim_hidden2': 30, 'hidden_act_func2': 'leaky_relu', 'dim_hidden3': 10, 'hidden_act_func3': 'leaky_relu', 'use_opt': 0, 'loss': 'MSE', 'output_act_func': 'lin', 'elapsed_time': 965.258496761322}\n",
      "results : {'train_loss_mean': 0.6066280423371537, 'train_loss_std': 0.04247690885007077, 'val_loss_mean': 0.996080661402065, 'val_loss_std': 0.08568511689414354, 'train_MEE_mean': 1.1552168064233856, 'train_MEE_std': 0.0525196409065305, 'val_MEE_mean': 1.4053126716730557, 'val_MEE_std': 0.047528080986303685}\n",
      "\n",
      "val_loss = 9.86e-01 +- 1.55e-01\n",
      "val_MEE = 1.41e+00 +- 8.87e-02\n",
      "hyperparameters : {'eta': 0.007, 'lam': 0.1, 'alpha': 1.2, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 25, 'hidden_act_func': 'leaky_relu', 'dim_hidden2': 20, 'hidden_act_func2': 'leaky_relu', 'dim_hidden3': 10, 'hidden_act_func3': 'leaky_relu', 'use_opt': 0, 'loss': 'MSE', 'output_act_func': 'lin', 'elapsed_time': 816.592182636261}\n",
      "results : {'train_loss_mean': 0.6276093614391038, 'train_loss_std': 0.029225157919553525, 'val_loss_mean': 0.9857502159998803, 'val_loss_std': 0.15482568844486844, 'train_MEE_mean': 1.1741552349665352, 'train_MEE_std': 0.021732210060862737, 'val_MEE_mean': 1.4134638715563494, 'val_MEE_std': 0.08869079820320264}\n",
      "\n",
      "val_loss = 9.89e-01 +- 1.55e-01\n",
      "val_MEE = 1.42e+00 +- 6.11e-02\n",
      "hyperparameters : {'eta': 0.007, 'lam': 0.1, 'alpha': 1.2, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 25, 'hidden_act_func': 'leaky_relu', 'dim_hidden2': 30, 'hidden_act_func2': 'leaky_relu', 'dim_hidden3': 10, 'hidden_act_func3': 'leaky_relu', 'use_opt': 0, 'loss': 'MSE', 'output_act_func': 'lin', 'elapsed_time': 961.7053263187408}\n",
      "results : {'train_loss_mean': 0.6227341462830995, 'train_loss_std': 0.03774615380658893, 'val_loss_mean': 0.9892311195518915, 'val_loss_std': 0.15456279052081337, 'train_MEE_mean': 1.169439455644235, 'train_MEE_std': 0.03990456838400436, 'val_MEE_mean': 1.4188123370347285, 'val_MEE_std': 0.0610818039392476}\n",
      "\n",
      "val_loss = 1.00e+00 +- 1.53e-01\n",
      "val_MEE = 1.43e+00 +- 5.86e-02\n",
      "hyperparameters : {'eta': 0.009, 'lam': 0.1, 'alpha': 0.9, 'epochs': 500, 'n_batch': 150, 'scale_eta_batchsize': None, 'dim_hidden': 25, 'hidden_act_func': 'leaky_relu', 'dim_hidden2': 30, 'hidden_act_func2': 'leaky_relu', 'dim_hidden3': 10, 'hidden_act_func3': 'leaky_relu', 'use_opt': 0, 'loss': 'MSE', 'output_act_func': 'lin', 'elapsed_time': 961.6471393108368}\n",
      "results : {'train_loss_mean': 0.6127568720855837, 'train_loss_std': 0.06987113433653175, 'val_loss_mean': 1.004555475340533, 'val_loss_std': 0.15325279259376035, 'train_MEE_mean': 1.1537013105476401, 'train_MEE_std': 0.07430393179870273, 'val_MEE_mean': 1.4253848800460909, 'val_MEE_std': 0.05860016005184126}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best {how_many} hyperparameter sets by their {sorting_key}\n",
    "\n",
    "how_many = 5 # how many elements to print\n",
    "sorting_key = 'val_MEE_mean' # value on which the sorting is performed\n",
    "p_best = []\n",
    "\n",
    "p_to_sort = [[x, x['results'][sorting_key]] for x in param_grid]\n",
    "p_best_sorted = sorted(p_to_sort, key=lambda x:x[1])\n",
    "\n",
    "for p_comb,loss in p_best_sorted[:how_many]:\n",
    "    p_best.append(p_comb)\n",
    "    tmp_dict = p_comb.copy()\n",
    "    results = tmp_dict.pop('results')\n",
    "    print(f\"val_loss = {results['val_loss_mean']:.2e} +- {results['val_loss_std']:.2e}\")\n",
    "    print(f\"val_MEE = {results['val_MEE_mean']:.2e} +- {results['val_MEE_std']:.2e}\")\n",
    "    print(f'hyperparameters : {tmp_dict}')\n",
    "    print(f'results : {results}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 7.665e+02, test_loss: 7.473e+02; train_MEE: 4.282e+01, test_MEE: 4.266e+01  lr : 0.009\n",
      "Epoch 1: train_loss: 7.402e+02, test_loss: 7.210e+02; train_MEE: 4.214e+01, test_MEE: 4.195e+01  lr : 0.009\n",
      "Epoch 2: train_loss: 6.978e+02, test_loss: 6.749e+02; train_MEE: 4.100e+01, test_MEE: 4.061e+01  lr : 0.009\n",
      "Epoch 3: train_loss: 6.075e+02, test_loss: 5.805e+02; train_MEE: 3.844e+01, test_MEE: 3.773e+01  lr : 0.009\n",
      "Epoch 4: train_loss: 4.638e+02, test_loss: 4.235e+02; train_MEE: 3.373e+01, test_MEE: 3.228e+01  lr : 0.009\n",
      "Epoch 5: train_loss: 2.859e+02, test_loss: 2.562e+02; train_MEE: 2.632e+01, test_MEE: 2.498e+01  lr : 0.009\n",
      "Epoch 6: train_loss: 1.592e+02, test_loss: 1.459e+02; train_MEE: 2.003e+01, test_MEE: 1.917e+01  lr : 0.009\n",
      "Epoch 7: train_loss: 1.120e+02, test_loss: 1.065e+02; train_MEE: 1.695e+01, test_MEE: 1.642e+01  lr : 0.009\n",
      "Epoch 8: train_loss: 1.091e+02, test_loss: 1.031e+02; train_MEE: 1.681e+01, test_MEE: 1.634e+01  lr : 0.009\n",
      "Epoch 9: train_loss: 8.392e+01, test_loss: 7.903e+01; train_MEE: 1.472e+01, test_MEE: 1.421e+01  lr : 0.009\n",
      "Epoch 10: train_loss: 6.617e+01, test_loss: 6.325e+01; train_MEE: 1.294e+01, test_MEE: 1.259e+01  lr : 0.009\n",
      "Epoch 11: train_loss: 5.062e+01, test_loss: 4.841e+01; train_MEE: 1.134e+01, test_MEE: 1.099e+01  lr : 0.009\n",
      "Epoch 12: train_loss: 3.783e+01, test_loss: 3.650e+01; train_MEE: 9.682e+00, test_MEE: 9.524e+00  lr : 0.009\n",
      "Epoch 13: train_loss: 3.078e+01, test_loss: 3.132e+01; train_MEE: 8.725e+00, test_MEE: 8.796e+00  lr : 0.009\n",
      "Epoch 14: train_loss: 2.382e+01, test_loss: 2.448e+01; train_MEE: 7.667e+00, test_MEE: 7.754e+00  lr : 0.009\n",
      "Epoch 15: train_loss: 1.863e+01, test_loss: 1.876e+01; train_MEE: 6.677e+00, test_MEE: 6.690e+00  lr : 0.009\n",
      "Epoch 16: train_loss: 1.495e+01, test_loss: 1.511e+01; train_MEE: 5.958e+00, test_MEE: 5.982e+00  lr : 0.009\n",
      "Epoch 17: train_loss: 1.260e+01, test_loss: 1.268e+01; train_MEE: 5.508e+00, test_MEE: 5.509e+00  lr : 0.009\n",
      "Epoch 18: train_loss: 1.093e+01, test_loss: 1.099e+01; train_MEE: 5.187e+00, test_MEE: 5.131e+00  lr : 0.009\n",
      "Epoch 19: train_loss: 9.541e+00, test_loss: 9.805e+00; train_MEE: 4.813e+00, test_MEE: 4.844e+00  lr : 0.009\n",
      "Epoch 20: train_loss: 8.299e+00, test_loss: 8.590e+00; train_MEE: 4.456e+00, test_MEE: 4.479e+00  lr : 0.009\n",
      "Epoch 21: train_loss: 7.305e+00, test_loss: 7.584e+00; train_MEE: 4.166e+00, test_MEE: 4.188e+00  lr : 0.009\n",
      "Epoch 22: train_loss: 6.705e+00, test_loss: 6.862e+00; train_MEE: 3.982e+00, test_MEE: 3.992e+00  lr : 0.009\n",
      "Epoch 23: train_loss: 6.021e+00, test_loss: 6.238e+00; train_MEE: 3.755e+00, test_MEE: 3.790e+00  lr : 0.009\n",
      "Epoch 24: train_loss: 5.441e+00, test_loss: 5.672e+00; train_MEE: 3.574e+00, test_MEE: 3.623e+00  lr : 0.009\n",
      "Epoch 25: train_loss: 5.013e+00, test_loss: 5.218e+00; train_MEE: 3.438e+00, test_MEE: 3.470e+00  lr : 0.009\n",
      "Epoch 26: train_loss: 4.632e+00, test_loss: 4.888e+00; train_MEE: 3.296e+00, test_MEE: 3.369e+00  lr : 0.009\n",
      "Epoch 27: train_loss: 4.363e+00, test_loss: 4.524e+00; train_MEE: 3.185e+00, test_MEE: 3.219e+00  lr : 0.009\n",
      "Epoch 28: train_loss: 4.092e+00, test_loss: 4.301e+00; train_MEE: 3.083e+00, test_MEE: 3.135e+00  lr : 0.009\n",
      "Epoch 29: train_loss: 3.880e+00, test_loss: 4.057e+00; train_MEE: 2.996e+00, test_MEE: 3.038e+00  lr : 0.009\n",
      "Epoch 30: train_loss: 3.686e+00, test_loss: 3.897e+00; train_MEE: 2.913e+00, test_MEE: 2.976e+00  lr : 0.009\n",
      "Epoch 31: train_loss: 3.539e+00, test_loss: 3.763e+00; train_MEE: 2.863e+00, test_MEE: 2.927e+00  lr : 0.009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Layer(hidden_layer, \u001b[38;5;241m3\u001b[39m, best_comb\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_act_func\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer, output_layer, best_comb\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[MEE])\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_comb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\NeuralNetwork.py:259\u001b[0m, in \u001b[0;36mNeuralNetwork.retrain\u001b[1;34m(self, input, target, epochs, eta, lam, alpha, n_batch, test_data, early_stopping, reduce_eta, verbose, use_opt)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m input_new[:,k\u001b[38;5;241m*\u001b[39mn_batch:(k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mn_batch]\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m target_new[:,k\u001b[38;5;241m*\u001b[39mn_batch:(k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mn_batch]\n\u001b[1;32m--> 259\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_history_batch(history, y_pred_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mbackward(lossfunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_lossfunc, last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:36\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:36\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UNI\\LM_1\\MachineLearning\\ML_prj\\notebooks\\Layer.py:36\u001b[0m, in \u001b[0;36mLayer.forward\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_layer\u001b[38;5;241m.\u001b[39mforward()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Permorm retraining on the best {how_many} sets and print loss and MEE graphs.\n",
    "\n",
    "retraining_epochs = 250\n",
    "print_best = True # print the best results on all graphs\n",
    "\n",
    "for i,p_comb in enumerate(p_best):\n",
    "\n",
    "    best_comb = p_comb.copy()\n",
    "\n",
    "    best_comb['epochs'] = retraining_epochs\n",
    "\n",
    "    results = best_comb.pop('results')\n",
    "    if best_comb['n_batch'] == 'batch':\n",
    "        best_comb['n_batch'] = X_train.shape[1]\n",
    "    elapsed_time = best_comb.pop('elapsed_time')\n",
    "    if best_comb['scale_eta_batchsize'] == 'lin':\n",
    "        best_comb['eta'] = best_comb['eta'] * best_comb['n_batch']\n",
    "    if best_comb['scale_eta_batchsize'] == 'sqrt':\n",
    "        best_comb['eta'] = best_comb['eta'] * np.sqrt(best_comb['n_batch'])\n",
    "    best_comb.pop('scale_eta_batchsize')\n",
    "\n",
    "    # ----------------------- MODEL ----------------------------\n",
    "    \n",
    "    input_layer = Input(X_train.shape[0])\n",
    "    hidden_layer = Layer(input_layer, best_comb.pop('dim_hidden'), best_comb.pop('hidden_act_func'))\n",
    "    o = 2\n",
    "    while True:\n",
    "        if f'dim_hidden{o}' in best_comb.keys():\n",
    "            hidden_layer = Layer(hidden_layer, best_comb.pop(f'dim_hidden{o}'), best_comb.pop(f'hidden_act_func{o}'))\n",
    "            o += 1\n",
    "        else: break\n",
    "    output_layer = Layer(hidden_layer, 3, best_comb.pop('output_act_func'))\n",
    "\n",
    "    model = NeuralNetwork(input_layer, output_layer, best_comb.pop('loss'), metrics=[MEE])\n",
    "    history = model.retrain(X_train, y_train.reshape((3,X_train.shape[1])), test_data = [X_test,y_test.reshape((3,X_test.shape[1]))], **best_comb)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    if i == 0:\n",
    "        best_train_loss, best_test_loss = history['train_loss'], history['test_loss']\n",
    "        best_train_MEE, best_test_MEE = history['train_MEE'], history['test_MEE']\n",
    "\n",
    "    plt.figure(i, figsize=(30,10))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['train_loss'],label='train_loss')\n",
    "    plt.plot(history['test_loss'], label='test_loss')\n",
    "    if (i > 0) and (print_best == True):\n",
    "        plt.plot(best_train_loss,'--',label='best_train_loss')\n",
    "        plt.plot(best_test_loss, '--', label='best_test_loss')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('Loss functions', size=15)\n",
    "    plt.title('train_loss vs test_loss', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['train_MEE'],label='train_MEE')\n",
    "    plt.plot(history['test_MEE'], label='test_MEE')\n",
    "    if (i > 0) and (print_best == True):\n",
    "        plt.plot(best_train_MEE,'--',label='best_train_MEE')\n",
    "        plt.plot(best_test_MEE, '--', label='best_test_MEE')\n",
    "    plt.xlabel('Epochs', size=15)\n",
    "    plt.ylabel('MEE', size=15)\n",
    "    plt.title('train_MEE vs test_MEE', size=18)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(seed):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.58526844 2.1846418  6.79919952 7.11004665 7.14118482 0.5398932\n",
      " 0.13095949 8.0790181  8.17264435 3.85478113]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(function(232323))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
